{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from scipy import stats\n",
    "import uproot\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creating the noise file \n",
    "def open_noise(filename) :\n",
    "    noise0=uproot.open(filename) #using uproot to open the root file \n",
    "    noise1=noise0['pixTree']\n",
    "    noise=pd.DataFrame(noise1['fData'].array(library=\"np\"))\n",
    "    noise=noise[noise.duplicated(subset=['row','col'])==True]\n",
    "    noise.drop_duplicates(subset=['row','col'],inplace=True)  #one consider a pixel tobe noisy xhen on a short run (<1minute), with no source it declares a hit more than one time.\n",
    "    X_noise=np.array(noise.col+((noise.chipId-4)*1024)) #changing the coordinates \n",
    "    Y_noise=np.array(noise.row)\n",
    "    return X_noise,Y_noise\n",
    "\n",
    "#put in the Noise data \n",
    "Noise1=open_noise('../Noise1')\n",
    "Noise2=open_noise('../Noise2')\n",
    "Noise3=open_noise('../Noise3')\n",
    "Noise4=open_noise('../Noise4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the root file and getting the tree (the root file are multinoiseScan_Date_Hour_RUNXX-B0-ladderX.root)\n",
    "def open_file (filename):\n",
    "    file=uproot.open(filename)\n",
    "\n",
    "    file1=file['pixTree']\n",
    "    Data=file1['fData'].array(library=\"np\")\n",
    "    data=pd.DataFrame(Data)\n",
    "    data.col=((data.chipId-4)*1024)+data.col\n",
    "    return data\n",
    "\n",
    "data1=open_file(\"../Data1\")\n",
    "data2=open_file(\"../Data2\")\n",
    "data3=open_file(\"../Data3\")\n",
    "data4=open_file(\"../Data4\")\n",
    "fig, axes = plt.subplots(4)\n",
    "\n",
    "display(data1)  #show the table with the different entries\n",
    "axes[0].hist2d(data1.col,data1.row,bins=100,density=True) #plotting the data as a 2D histogram (at this point data from ladder 2 and 4 are flipped)\n",
    "axes[1].hist2d(data2.col,data2.row,bins=100,density=True)\n",
    "axes[2].hist2d(data3.col,data3.row,bins=100,density=True)\n",
    "axes[3].hist2d(data4.col,data4.row,bins=100,density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove noise \n",
    "def remove_noise (noise,data) :\n",
    "        n_0=data[data.col.isin(noise[0]) & data.row.isin(noise[1])].index\n",
    "        if len(n_0)>0:\n",
    "            data.drop(index=n_0,inplace=True)\n",
    "        return data \n",
    "\n",
    "\n",
    "data1_filtered=remove_noise(Noise1,data1)\n",
    "data2_filtered=remove_noise(Noise2,data2)\n",
    "data3_filtered=remove_noise(Noise3,data3)\n",
    "data4_filtered=remove_noise(Noise4,data4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Displaying the filtered data (Monitoring the experiment)\n",
    "fig, axes = plt.subplots(4)\n",
    "axes[0].hist2d(data1_filtered.col,data1_filtered.row,bins=[600,300],norm='symlog',cmin=1)\n",
    "axes[1].hist2d(data2_filtered.col,data2_filtered.row,bins=[600,300],norm='symlog',cmin=1)\n",
    "axes[2].hist2d(data3_filtered.col,data3_filtered.row,bins=[600,300],norm='symlog',cmin=1)\n",
    "axes[3].hist2d(data4_filtered.col,data4_filtered.row,bins=[600,300],norm='symlog',cmin=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flipping the data from the even plane in y \n",
    "def flip_data_row (data) :\n",
    "    data.row=524-data.row\n",
    "    return data\n",
    "\n",
    "flip_data_row(data2_filtered)\n",
    "flip_data_row(data4_filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First alignement of the telescope \n",
    "def track (Pos_1,Pos_2,z) :\n",
    "    x=((z-Pos_1[2])/(Pos_2[2]-Pos_1[2]))+Pos_1[0]\n",
    "    y=((z-Pos_1[2])/(Pos_2[2]-Pos_1[2]))+Pos_1[1]\n",
    "    return [x,y]\n",
    "\n",
    "#for this first alignement, we just consider the mean in x and y of the hits and we built track 2 by 2, then moving the other plane to be on this track\n",
    "def alignement_telescope (DATA,Z) : \n",
    "    for i in range (len(DATA)) :\n",
    "        for j in range (len(DATA)-1,i,-1) :\n",
    "            for k in range (len(DATA)) :\n",
    "                if k!=j and k!=i :\n",
    "                    print(i,j,k)\n",
    "                    print(Z[j]-Z[i])\n",
    "                    Moved=track([np.mean(DATA[i].col),np.mean(DATA[i].row),Z[i]],[np.mean(DATA[j].col),np.mean(DATA[j].row),Z[j]],Z[k])\n",
    "                    print(Moved[0],Moved[1])\n",
    "                    print(np.mean(DATA[k].col)-Moved[0],np.mean(DATA[k].row)-Moved[1])\n",
    "                    DATA[k].row=DATA[k].row+(Moved[1]-np.mean(DATA[k].row))\n",
    "                    DATA[k].col=DATA[k].col+(Moved[0]-np.mean(DATA[k].col))\n",
    "\n",
    "\n",
    "    return DATA\n",
    "\n",
    "\n",
    "Z=[0,10.6,145,155.6] #coordinates of the differents planes of BANCO\n",
    "hitchipId=8\n",
    "DATA =[data1_filtered[data1_filtered.chipId==hitchipId],data2_filtered[data2_filtered.chipId==hitchipId],data3_filtered[data3_filtered.chipId==hitchipId],data4_filtered[data4_filtered.chipId==hitchipId]] #restriction to the useful chip\n",
    "DATA1=alignement_telescope(DATA,Z) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the data aligned\n",
    "\n",
    "fig, axes = plt.subplots(4)\n",
    "axes[0].hist2d(DATA1[0].col,DATA1[0].row,bins=[600,300],norm='symlog',cmin=1)\n",
    "axes[1].hist2d(DATA1[1].col,DATA1[1].row,bins=[600,300],norm='symlog',cmin=1)\n",
    "axes[2].hist2d(DATA1[2].col,DATA1[2].row,bins=[600,300],norm='symlog',cmin=1)\n",
    "axes[3].hist2d(DATA1[3].col,DATA1[3].row,bins=[600,300],norm='symlog',cmin=1)\n",
    "\n",
    "axes[0].axis('scaled')\n",
    "axes[1].axis('scaled')\n",
    "axes[2].axis('scaled')\n",
    "axes[3].axis('scaled')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting superposed\n",
    "fig, axes = plt.subplots()\n",
    "plt.hist2d(DATA1[0].col,DATA1[0].row,bins=[600,300],norm='symlog',cmap='Greens')\n",
    "plt.hist2d(DATA1[1].col,DATA1[1].row,bins=[600,300],norm='symlog',cmap='Blues',alpha=0.2)\n",
    "plt.hist2d(DATA1[2].col,DATA1[2].row,bins=[600,300],norm='symlog',cmap='Reds',alpha=0.2)\n",
    "plt.hist2d(DATA1[3].col,DATA1[3].row,bins=[600,300],norm='symlog',cmap='viridis',alpha=0.2,cmin=1)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering with Agglomerative Clustering (this method use a clustering method based on dichotomy )\n",
    "\n",
    "def Clustering (data) :\n",
    "    n=0\n",
    "    Cluster=[]\n",
    "    L=[]\n",
    "    for i in range(max(data.trgNum)+1) :\n",
    "        if data[data.trgNum==i].empty ==False :\n",
    "            if (i in L) ==False :\n",
    "                L.append(i)\n",
    "                data_trgNum= data[data.trgNum==i] \n",
    "                if len(data_trgNum)!=1 :\n",
    "                    X=data_trgNum[['row','col']].to_numpy()\n",
    "                    clustering = AgglomerativeClustering(n_clusters=None,distance_threshold=2,metric='euclidean').fit(X)\n",
    "                    labels = clustering.labels_ \n",
    "                    for i in labels :\n",
    "                        Cluster.append(i+n)\n",
    "                    n=max(labels)+1+n\n",
    "                else :\n",
    "                    Cluster.append(n)\n",
    "                    n+=1\n",
    "    return Cluster\n",
    "\n",
    "Cluster1=Clustering(DATA1[0])\n",
    "Cluster2=Clustering(DATA1[1])\n",
    "Cluster3=Clustering(DATA1[2])\n",
    "Cluster4=Clustering(DATA1[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the clusters to the right data\n",
    "\n",
    "data1_clusterized = DATA1[0]\n",
    "data1_clusterized['cluster']=Cluster1\n",
    "data2_clusterized = DATA1[1]\n",
    "data2_clusterized['cluster']=Cluster2\n",
    "data3_clusterized = DATA1[2]\n",
    "data3_clusterized['cluster']=Cluster3\n",
    "data4_clusterized = DATA1[3]\n",
    "data4_clusterized['cluster']=Cluster4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing barycenter\n",
    "\n",
    "def reduce_by_barycenter (data) :\n",
    "    data['Xbar'] = 0\n",
    "    data['Ybar'] = 0\n",
    "    for i in range (1,data.cluster.max()+1) :\n",
    "        data.loc[data['cluster']==i,'Xbar']=data[data['cluster']==i].col.mean()\n",
    "        data.loc[data['cluster']==i,'Ybar']=data[data['cluster']==i].row.mean()\n",
    "    B=data.drop_duplicates(subset=['Xbar','Ybar','cluster'],keep='first',inplace=False)\n",
    "    return B\n",
    "\n",
    "#data redyuced to only the barycenter of the cluster \n",
    "data1_reduced=reduce_by_barycenter (data1_clusterized)\n",
    "data2_reduced=reduce_by_barycenter (data2_clusterized)\n",
    "data3_reduced=reduce_by_barycenter (data3_clusterized)\n",
    "data4_reduced=reduce_by_barycenter (data4_clusterized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the data \n",
    "def chi2 (xexp,xfit): #computing chi2\n",
    "    chi2 =0 \n",
    "    for i in range (len(xexp)):\n",
    "        chi2+=((xexp[i]-xfit[i])**2)/xexp[i]\n",
    "    return chi2\n",
    "\n",
    "def tracking (X,Y,Z0) : #getting the tracks we want and there score (we consider 2 going from 0 to 160, taking into account all the planes )\n",
    "    model_X = LinearRegression()\n",
    "    model_Y= LinearRegression()\n",
    "    Z0=np.array(Z0)\n",
    "    model_X.fit(Z0.reshape(-1,1),X)\n",
    "    model_Y.fit(Z0.reshape(-1,1),Y)\n",
    "    X_fit=model_X.predict(np.arange(0,160).reshape((-1, 1)))\n",
    "    Y_fit=model_Y.predict((np.arange(0,160).reshape((-1, 1))))\n",
    "    r_sq_X = model_X.score(Z0.reshape(-1,1),X)\n",
    "    r_sq_Y=model_Y.score(Z0.reshape(-1,1),Y)\n",
    "    chi2_x=chi2(X,[X_fit[0],X_fit[11],X_fit[146],X_fit[156]])\n",
    "    chi2_y=chi2(Y,[Y_fit[0],Y_fit[11],Y_fit[146],Y_fit[156]])\n",
    "    return ([X_fit,Y_fit],[r_sq_X,r_sq_Y],[chi2_x,chi2_y])\n",
    "\n",
    "#computing residuals\n",
    "def distance_from_fit (xexp,xfit):\n",
    "    d=0 \n",
    "    for i in range (len(xexp)):\n",
    "        d+=(xexp[i]-xfit[i])/4\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Alignement from the tracking : In this more precise alignement technique we compute all the residuals from a track (3 points fitting, distance from the track of the 4th one)\n",
    "\n",
    "def precise_alignement (DATA,Z0) :\n",
    "    Distances_X=[[],[],[],[]]\n",
    "    Distances_Y=[[],[],[],[]]\n",
    "    for i in range(max(data1.trgNum)) :\n",
    "        if (len(DATA[0][DATA[0].trgNum==i]) ==1) and (len(DATA[1][DATA[1].trgNum==i])==1) and (len(DATA[2][DATA[2].trgNum==i]) ==1) and (len(DATA[3][DATA[3].trgNum==i]) ==1):\n",
    "            for k in range(4):\n",
    "                X=[]\n",
    "                Y=[]\n",
    "                Z=[]\n",
    "                for j in range (4):\n",
    "                    if j!=k:\n",
    "                        X.append(DATA[j].at[DATA[j][DATA[j].trgNum==i],'Xbar'])\n",
    "                        Y.append(DATA[j].at[DATA[j][DATA[j].trgNum==i],'Ybar'])\n",
    "                        Z.append(int(Z0[j]))\n",
    "                L=tracking (X,Y,Z)\n",
    "                distance_x=L[0][0][int(Z0[k])]-DATA[k].at[DATA[k][DATA[k].trgNum==i],'Xbar']\n",
    "                distance_y=L[0][1][int(Z0[k])]-DATA[k].at[DATA[k][DATA[k].trgNum==i],'Ybar']\n",
    "                Distances_X[k].append(distance_x)\n",
    "                Distances_Y[k].append(distance_y)\n",
    "    return Distances_X,Distances_Y\n",
    "\n",
    "\n",
    "\n",
    "DATA=[data1_reduced,data2_reduced,data3_reduced,data4_reduced]\n",
    "Z=[0,10.6,145,155.6]\n",
    "Distances=precise_alignement(DATA,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving from the correction that we had previously\n",
    "def move (data,x,y):\n",
    "    data.row=data.row+x\n",
    "    data.col=data.col+y\n",
    "\n",
    "for i in range(4) :\n",
    "    move(DATA[i],np.mean(Distances[0][i]),np.mean(Distances[1][i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the mean resolution (Distances from the track in X and in Y), useful to get the quality of the alignement\n",
    "\n",
    "def mean_resolution (data1,data2,data3,data4,Z) :\n",
    "    Resolutions_X =[]\n",
    "    Resolutions_Y =[]\n",
    "\n",
    "    Tracking=[]\n",
    "    for i in range(max(data1.trgNum)) :\n",
    "        if (len(data1[data1.trgNum==i]) ==1) and (len(data4[data4.trgNum==i])==1) and (len(data2[data2.trgNum==i]) ==1) and (len(data3[data3.trgNum==i]) ==1):\n",
    "            X=[data1.at[data1[data1.trgNum==i],'Xbar'],data2.at[data2[data2.trgNum==i],'Xbar'],data3.at[data3[data3.trgNum==i],'Xbar'],data4.at[data4[data4.trgNum==i],'Xbar']]\n",
    "            Y=[data1.at[data1[data1.trgNum==i],'Ybar'],data2.at[data2[data2.trgNum==i],'Ybar'],data3.at[data3[data3.trgNum==i],'Ybar'],data4.at[data4[data4.trgNum==i],'Ybar']]\n",
    "            L=tracking (X,Y,Z)\n",
    "            Resolutions_X.append(distance_from_fit(X,[L[0][0][0],L[0][0][11],L[0][0][146],L[0][0][156]]))\n",
    "            Resolutions_Y.append(distance_from_fit(Y,[L[0][1][0],L[0][1][11],L[0][1][146],L[0][1][156]]))\n",
    "            Tracking.append([L,i])\n",
    "            if (distance_from_fit(X,[L[0][0][0],L[0][0][11],L[0][0][146],L[0][0][156]]))>150 :\n",
    "                print(int(i))\n",
    "\n",
    "    return(Resolutions_X,Resolutions_Y)\n",
    "Resolutions=mean_resolution(DATA[0],DATA[1],DATA[2],DATA[3],Z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
