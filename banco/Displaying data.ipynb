{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from scipy import stats\n",
    "import uproot\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creating the noise file \n",
    "def open_noise(filename) :\n",
    "    noise0=uproot.open(filename) #using uproot to open the root file \n",
    "    noise1=noise0['pixTree']\n",
    "    noise=pd.DataFrame(noise1['fData'].array(library=\"np\"))\n",
    "    noise=noise[noise.duplicated(subset=['row','col'])==True]\n",
    "    noise.drop_duplicates(subset=['row','col'],inplace=True)  #one consider a pixel tobe noisy xhen on a short run (<1minute), with no source it declares a hit more than one time.\n",
    "    X_noise=np.array(noise.col+((noise.chipId-4)*1024)) #changing the coordinates \n",
    "    Y_noise=np.array(noise.row)\n",
    "    return X_noise,Y_noise\n",
    "\n",
    "#put in the Noise data \n",
    "Noise1=open_noise('../Noise1')\n",
    "Noise2=open_noise('../Noise2')\n",
    "Noise3=open_noise('../Noise3')\n",
    "Noise4=open_noise('../Noise4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the root file and getting the tree\n",
    "def open_file (filename,id):\n",
    "    file=uproot.open(filename)\n",
    "    file1=file['pixTree']\n",
    "    Data=file1['fData'].array(library=\"np\")\n",
    "    data=pd.DataFrame(Data)\n",
    "    data['ldr']=id\n",
    "    data.col=((data.chipId-4)*1024)+data.col\n",
    "    return data\n",
    "\n",
    "data=open_file(\"../Data1\")\n",
    "data2=open_file(\"../Data2\")\n",
    "data3=open_file(\"../Data3\")\n",
    "data4=open_file(\"../Data4\")\n",
    "\n",
    "data=pd.concat([data,data2])\n",
    "data=pd.concat([data,data3])\n",
    "data=pd.concat([data,data4])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(4)\n",
    "\n",
    "display(data) #show the table with the different entries\n",
    "axes[0].hist2d(data[data.ldr==1].col,data[data.ldr==1].row,bins=100,density=True) #plotting the data as a 2D histogram (at this point data from ladder 2 and 4 are flipped)\n",
    "axes[1].hist2d(data[data.ldr==2].col,data[data.ldr==2].row,bins=100,density=True)\n",
    "axes[2].hist2d(data[data.ldr==3].col,data[data.ldr==3].row,bins=100,density=True)\n",
    "axes[3].hist2d(data[data.ldr==4].col,data[data.ldr==4].row,bins=100,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove noisy pixels \n",
    "def remove_noise (noise,data) :\n",
    "        n_0=data[data.col.isin(noise[0]) & data.row.isin(noise[1])].index\n",
    "        if len(n_0)>0:\n",
    "            data.drop(index=n_0,inplace=True)\n",
    "        return data \n",
    "\n",
    "\n",
    "data_filtered=remove_noise(Noise1,data[data.ldr==1])\n",
    "data_filtered=pd.concat([data_filtered,remove_noise(Noise2,data[data.ldr==2])])\n",
    "data_filtered=pd.concat([data_filtered,remove_noise(Noise2,data[data.ldr==3])])\n",
    "data_filtered=pd.concat([data_filtered,remove_noise(Noise2,data[data.ldr==4])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Displaying the filtered data (Monitoring the experiment)\n",
    "display(data_filtered)\n",
    "fig, axes = plt.subplots(4)\n",
    "axes[0].hist2d(data_filtered[(data_filtered.ldr==1)&(data_filtered.chipId==8)].col,data_filtered[(data_filtered.ldr==1)&(data_filtered.chipId==8)].row,bins=[600,300],norm='symlog')\n",
    "axes[1].hist2d(data_filtered[(data_filtered.ldr==2)&(data_filtered.chipId==8)].col,data_filtered[(data_filtered.ldr==2)&(data_filtered.chipId==8)].row,bins=[600,300],norm='symlog')\n",
    "axes[2].hist2d(data_filtered[(data_filtered.ldr==3)&(data_filtered.chipId==8)].col,data_filtered[(data_filtered.ldr==3)&(data_filtered.chipId==8)].row,bins=[600,300],norm='symlog')\n",
    "axes[3].hist2d(data_filtered[(data_filtered.ldr==4)&(data_filtered.chipId==8)].col,data_filtered[(data_filtered.ldr==4)&(data_filtered.chipId==8)].row,bins=[600,300],norm='symlog')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flipping the data from the even plane in y \n",
    "def flip_data_row (data) :\n",
    "    data.row=524-data.row\n",
    "    return data\n",
    "\n",
    "data_filtered[(data_filtered.ldr==2)]=flip_data_row(data_filtered[(data_filtered.ldr==2)])\n",
    "data_filtered[(data_filtered.ldr==4)]=flip_data_row(data_filtered[(data_filtered.ldr==4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alignement of the telescope \n",
    "def track (Pos_1,Pos_2,z) :\n",
    "    x=((z-Pos_1[2])/(Pos_2[2]-Pos_1[2]))+Pos_1[0]\n",
    "    y=((z-Pos_1[2])/(Pos_2[2]-Pos_1[2]))+Pos_1[1]\n",
    "    return [x,y]\n",
    "\n",
    "#for this first alignement, we just consider the mean in x and y of the hits and we built track 2 by 2, then moving the other plane to be on this track\n",
    "def alignement_telescope (DATA,Z) :\n",
    "    for i in range (max(DATA.ldr)) :\n",
    "        for j in range (max(DATA.ldr)-1,i,-1) :\n",
    "            for k in range (max(DATA.ldr)) :\n",
    "                if k!=j and k!=i :\n",
    "                    Moved=track([np.mean(DATA[DATA.ldr==i+1].col),np.mean(DATA[DATA.ldr==i+1].row),Z[i]],[np.mean(DATA[DATA.ldr==j+1].col),np.mean(DATA[DATA.ldr==j+1].row),Z[j]],Z[k])\n",
    "                    DATA.loc[DATA.ldr==k+1,'row']=DATA[DATA.ldr==k+1].row+(Moved[1]-np.mean(DATA[DATA.ldr==k+1].row))\n",
    "                    DATA.loc[DATA.ldr==k+1,'col']=DATA[DATA.ldr==k+1].col+(Moved[0]-np.mean(DATA[DATA.ldr==k+1].col))\n",
    "    return DATA\n",
    "\n",
    "\n",
    "Z=[0,10.6,145,155.6]#coordinates of the differents planes of BANCO\n",
    "data_aligned=alignement_telescope(data_filtered[data_filtered.chipId==8],Z)\n",
    "display(data_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting superposed (to see if planes are aligned)\n",
    "fig, axes = plt.subplots()\n",
    "plt.hist2d(data_aligned[data_aligned.ldr==1].col,data_aligned[data_aligned.ldr==1].row,bins=[600,300],norm='symlog',cmap='Greens')\n",
    "plt.hist2d(data_aligned[data_aligned.ldr==2].col,data_aligned[data_aligned.ldr==2].row,bins=[600,300],norm='symlog',cmap='Blues',alpha=0.2)\n",
    "plt.hist2d(data_aligned[data_aligned.ldr==3].col,data_aligned[data_aligned.ldr==3].row,bins=[600,300],norm='symlog',cmap='Reds',alpha=0.2)\n",
    "plt.hist2d(data_aligned[data_aligned.ldr==4].col,data_aligned[data_aligned.ldr==4].row,bins=[600,300],norm='symlog',cmap='viridis',alpha=0.2,cmin=1)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering with Agglomerative Clustering (this method use a clustering method based on dichotomy )\n",
    "\n",
    "def Clustering (data) :\n",
    "    n=0\n",
    "    Cluster=[]\n",
    "    L=[]\n",
    "    for i in range(max(data.trgNum)+1) :\n",
    "        if data[data.trgNum==i].empty ==False :\n",
    "            if (i in L) ==False :\n",
    "                L.append(i)\n",
    "                data_trgNum= data[data.trgNum==i] \n",
    "                if len(data_trgNum)!=1 :\n",
    "                    X=data_trgNum[['row','col']].to_numpy()\n",
    "                    clustering = AgglomerativeClustering(n_clusters=None,distance_threshold=2,metric='euclidean').fit(X)\n",
    "                    labels = clustering.labels_ \n",
    "                    for i in labels :\n",
    "                        Cluster.append(i+n)\n",
    "                    n=max(labels)+1+n\n",
    "                else :\n",
    "                    Cluster.append(n)\n",
    "                    n+=1\n",
    "    return Cluster\n",
    "\n",
    "Clusters=[]\n",
    "for i in range (max(data_aligned.ldr)):\n",
    "    Clusters.append(Clustering(data_aligned[data_aligned.ldr==i+1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the clusters to the right data\n",
    "\n",
    "data_clusterized=data_aligned.copy()\n",
    "data_clusterized['cluster']=0\n",
    "for i in range(max(data_clusterized.ldr)):\n",
    "    data_clusterized.loc[data_clusterized.ldr==i+1,'cluster']=np.array(Clusters[i])+max(data_clusterized.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#computing barycenter\n",
    "\n",
    "def reduce_by_barycenter (data) :\n",
    "    data['Xbar'] = 0\n",
    "    data['Ybar'] = 0\n",
    "    for i in range (1,data.cluster.max()+1) :\n",
    "        data.loc[data['cluster']==i,'Xbar']=data[data['cluster']==i].col.mean()\n",
    "        data.loc[data['cluster']==i,'Ybar']=data[data['cluster']==i].row.mean()\n",
    "    B=data.drop_duplicates(subset=['Xbar','Ybar','cluster'],keep='first',inplace=False)\n",
    "    return B\n",
    "\n",
    "\n",
    "data_reduced=reduce_by_barycenter (data_clusterized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the data \n",
    "def chi2 (xexp,xfit): #computing chi2\n",
    "    chi2 =0 \n",
    "    for i in range (len(xexp)):\n",
    "        chi2+=((xexp[i]-xfit[i])**2)/xexp[i]\n",
    "    return chi2\n",
    "\n",
    "def tracking (X,Y,Z0,t) : #getting the tracks we want and there residuals \n",
    "    slope_X, intercept_X= stats.linregress(Z0, X)\n",
    "    slope_Y, intercept_Y= stats.linregress(Z0, Y)\n",
    "    Mean_Residuals_X=np.mean((1-slope_X)*X-intercept_X)\n",
    "    Mean_Residuals_Y=np.mean((1-slope_Y)*Y-intercept_Y)\n",
    "    return pd.DataFrame({'trgNum':t,'Mean_Residuals_X':Mean_Residuals_X,'Mean_Residuals_Y':Mean_Residuals_Y,'slope_X':slope_X,'intercept_X':intercept_X,'slope_Y':slope_Y,'intercept_Y':intercept_Y})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Alignement from the tracking : In this more precise alignement technique we compute all the residuals from a track (3 points fitting, distance from the track of the 4th one)\n",
    "\n",
    "def precise_alignement (data,Z0) :\n",
    "    Distances_X=[[],[],[],[]]\n",
    "    Distances_Y=[[],[],[],[]]\n",
    "    for t in range(max(data.trgNum)) :\n",
    "        if (len(data[data.trgNum==t])==max(data.ldr) and data[data.trgNum==t].ldr.nunique() == data[data.trgNum==t].ldr.size):\n",
    "            for k in range(max(data.ldr)):\n",
    "                X=[]\n",
    "                Y=[]\n",
    "                Z=[]\n",
    "                for j in range (max(data.ldr)):\n",
    "                    if j!=k:\n",
    "                        X=[data.at[data[(data.trgNum==t)&(data.ldr==j+1)],'Xbar']]\n",
    "                        Y=[data.at[data[(data.trgNum==t)&(data.ldr==j+1)],'Ybar']]\n",
    "                        Z.append(Z0[j])\n",
    "                t=tracking (X,Y,Z)\n",
    "                distance_x=T['slope_X']*Z0[k]+T['intercept_X']-[data.at[data[(data.trgNum==t)&(data.ldr==k+1)],'Xbar']]\n",
    "                distance_y=T['slope_Y']*Z0[k]+T['intercept_Y']-[data.at[data[(data.trgNum==t)&(data.ldr==k+1)],'Ybar']]\n",
    "                Distances_X[k].append(distance_x)\n",
    "                Distances_Y[k].append(distance_y)\n",
    "    return pd.DataFrame({'dx':Distances_X,'dy':Distances_Y})\n",
    "\n",
    "\n",
    "\n",
    "Z=[0,10.6,145,155.6]\n",
    "Distances=precise_alignement(data_reduced,Z)\n",
    "print('x',np.mean(Distances['dx'][0]),np.mean(Distances['dx'][1]),np.mean(Distances['dx'][2]),np.mean(Distances['dx'][3]),'Y',np.mean(Distances['dy'][0]),np.mean(Distances['dy'][1]),np.mean(Distances['dy'][2]),np.mean(Distances['dy'][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving from the correction that we had previously\n",
    "def move (data,X,Y):\n",
    "    for ldr in range(max(data.ldr)) :\n",
    "        data.loc[data.ldr==ldr+1,'row']=data.row+np.mean(X[ldr])\n",
    "        data.loc[data.ldr==ldr+1,'col']=data.col+np.mean(Y[ldr])\n",
    "    return data\n",
    "\n",
    "\n",
    "data_aligned_2=move(data,Distances['dx'],Distances['dy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing all the tracks for a run \n",
    "\n",
    "def make_tracks (data,Z) :\n",
    "    Tracks=pd.DataFrame({{'trgNum':[],'Mean_Residuals_X':[],'Mean_Residuals_Y':[],'slope_X':[],'intercept_X':[],'slope_Y':[],'intercept_Y':[]}})\n",
    "    for t in range(max(data.trgNum)) :\n",
    "        if (len(data[data.trgNum==t])==max(data.ldr) and data[data.trgNum==t].ldr.nunique() == data[data.trgNum==t].ldr.size):\n",
    "            X=[data.at[data[(data.trgNum==t)&(data.ldr==i+1)],'Xbar'] for i in range (max(data.ldr))]\n",
    "            Y=[data.at[data[(data.trgNum==t)&(data.ldr==i+1)],'Ybar'] for i in range (max(data.ldr))]\n",
    "            T=tracking (X,Y,Z)\n",
    "            pd.concat(Tracks,T)\n",
    "    return Tracks\n",
    "\n",
    "\n",
    "Tracks=make_tracks(data_aligned,Z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
