{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from scipy import stats\n",
    "import uproot\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creating the noise file \n",
    "def open_noise(filename) :\n",
    "    noise0=uproot.open(filename) #using uproot to open the root file \n",
    "    noise1=noise0['pixTree']\n",
    "    noise=pd.DataFrame(noise1['fData'].array(library=\"np\"))\n",
    "    noise=noise[noise.duplicated(subset=['row','col'])==True]\n",
    "    noise.drop_duplicates(subset=['row','col'],inplace=True)  #one consider a pixel tobe noisy xhen on a short run (<1minute), with no source it declares a hit more than one time.\n",
    "    X_noise=np.array(noise.col+((noise.chipId-4)*1024)) #changing the coordinates \n",
    "    Y_noise=np.array(noise.row)\n",
    "    return X_noise,Y_noise\n",
    "\n",
    "#put in the Noise data \n",
    "Noise1=open_noise('../Noise1')\n",
    "Noise2=open_noise('../Noise2')\n",
    "Noise3=open_noise('../Noise3')\n",
    "Noise4=open_noise('../Noise4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the root file and getting the tree\n",
    "def open_file (filename,id):\n",
    "    file=uproot.open(filename)\n",
    "    file1=file['pixTree']\n",
    "    Data=file1['fData'].array(library=\"np\")\n",
    "    data=pd.DataFrame(Data)\n",
    "    data['ldr']=id\n",
    "    data.col=((data.chipId-4)*1024)+data.col\n",
    "    return data\n",
    "\n",
    "data=open_file(\"../Data1\",1)\n",
    "data2=open_file(\"../Data2\",2)\n",
    "data3=open_file(\"../Data3\",3)\n",
    "data4=open_file(\"../Data4\",4)\n",
    "\n",
    "data=pd.concat([data,data2])\n",
    "data=pd.concat([data,data3])\n",
    "data=pd.concat([data,data4])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(4)\n",
    "\n",
    "display(data) #show the table with the different entries\n",
    "axes[0].hist2d(data[data.ldr==1].col,data[data.ldr==1].row,bins=100,density=True) #plotting the data as a 2D histogram (at this point data from ladder 2 and 4 are flipped)\n",
    "axes[1].hist2d(data[data.ldr==2].col,data[data.ldr==2].row,bins=100,density=True)\n",
    "axes[2].hist2d(data[data.ldr==3].col,data[data.ldr==3].row,bins=100,density=True)\n",
    "axes[3].hist2d(data[data.ldr==4].col,data[data.ldr==4].row,bins=100,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove noisy pixels \n",
    "def remove_noise (noise,data) :\n",
    "        n_0=data[data.col.isin(noise[0]) & data.row.isin(noise[1])].index\n",
    "        if len(n_0)>0:\n",
    "            data.drop(index=n_0,inplace=True)\n",
    "        return data \n",
    "\n",
    "\n",
    "data_filtered=remove_noise(Noise1,data[data.ldr==1])\n",
    "data_filtered=pd.concat([data_filtered,remove_noise(Noise2,data[data.ldr==2])])\n",
    "data_filtered=pd.concat([data_filtered,remove_noise(Noise2,data[data.ldr==3])])\n",
    "data_filtered=pd.concat([data_filtered,remove_noise(Noise2,data[data.ldr==4])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Displaying the filtered data (Monitoring the experiment)\n",
    "display(data_filtered)\n",
    "fig, axes = plt.subplots(4)\n",
    "axes[0].hist2d(data_filtered[(data_filtered.ldr==1)&(data_filtered.chipId==8)].col,data_filtered[(data_filtered.ldr==1)&(data_filtered.chipId==8)].row,bins=[600,300],norm='symlog')\n",
    "axes[1].hist2d(data_filtered[(data_filtered.ldr==2)&(data_filtered.chipId==8)].col,data_filtered[(data_filtered.ldr==2)&(data_filtered.chipId==8)].row,bins=[600,300],norm='symlog')\n",
    "axes[2].hist2d(data_filtered[(data_filtered.ldr==3)&(data_filtered.chipId==8)].col,data_filtered[(data_filtered.ldr==3)&(data_filtered.chipId==8)].row,bins=[600,300],norm='symlog')\n",
    "axes[3].hist2d(data_filtered[(data_filtered.ldr==4)&(data_filtered.chipId==8)].col,data_filtered[(data_filtered.ldr==4)&(data_filtered.chipId==8)].row,bins=[600,300],norm='symlog')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flipping the data from the even plane in y \n",
    "def flip_data_row (data) :\n",
    "    data.row=512-data.row\n",
    "    return data\n",
    "\n",
    "data_filtered[(data_filtered.ldr==2)]=flip_data_row(data_filtered[(data_filtered.ldr==2)])\n",
    "data_filtered[(data_filtered.ldr==4)]=flip_data_row(data_filtered[(data_filtered.ldr==4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refocusing on the used chipId\n",
    "chipId=8\n",
    "data_focused=data_filtered[data_filtered.chipId==chipId] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting superposed (to see Misalignements)\n",
    "fig, axes = plt.subplots()\n",
    "plt.hist2d(data_focused[data_focused.ldr==1].col,data_focused[data_focused.ldr==1].row,bins=[600,300],norm='symlog',cmap='Greens')\n",
    "plt.hist2d(data_focused[data_focused.ldr==2].col,data_focused[data_focused.ldr==2].row,bins=[600,300],norm='symlog',cmap='Blues',alpha=0.2)\n",
    "plt.hist2d(data_focused[data_focused.ldr==3].col,data_focused[data_focused.ldr==3].row,bins=[600,300],norm='symlog',cmap='Reds',alpha=0.2)\n",
    "plt.hist2d(data_focused[data_focused.ldr==4].col,data_focused[data_focused.ldr==4].row,bins=[600,300],norm='symlog',cmap='viridis',alpha=0.2,cmin=1)\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering with DBSCAN  \n",
    "\n",
    "def Clustering (data) :\n",
    "    eps=1.5\n",
    "    n=0\n",
    "    Cluster=[]\n",
    "    L=[]\n",
    "    m=max(data.trgNum)\n",
    "    for i in range(m+1) :#scan each event\n",
    "        print('Doing clustering : ',(i*100)/m,' %',end='\\r')\n",
    "        if data[data.trgNum==i].empty ==False :#reove empty event\n",
    "            if (i in L) ==False :\n",
    "                L.append(i)\n",
    "                data_trgNum= data[data.trgNum==i] \n",
    "                if len(data_trgNum)!=1 : \n",
    "                    X=data_trgNum[['row','col']].to_numpy()\n",
    "                    clustering = DBSCAN(eps=eps,metric='euclidean',min_samples=1).fit(X) #computing the clusters : a cluster is a group of hits seperated by less than 1.5 pixels\n",
    "                    labels = clustering.labels_ \n",
    "                    for i in labels :\n",
    "                        Cluster.append(i+n)\n",
    "                    n=max(labels)+1+n\n",
    "                else :\n",
    "                    Cluster.append(n)\n",
    "                    n+=1\n",
    "    return Cluster\n",
    "\n",
    "\n",
    " data_clusterized=do_clusters(data_focused)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_clusters(data_focused): #we compute first the Clusters by ladder and them we put them all together in one DataFrame\n",
    "    Clusters=[]\n",
    "    for i in range (max(data_focused.ldr)):\n",
    "        Clusters.append(Clustering(data_focused[data_focused.ldr==i+1]))\n",
    "    #Setting the clusters to the right data\n",
    "    data_clusterized=data_focused.copy()\n",
    "    data_clusterized['cluster']=0\n",
    "    for i in range(max(data_clusterized.ldr)):\n",
    "        data_clusterized.loc[data_clusterized.ldr==i+1,'cluster']=np.array(Clusters[i])+max(data_clusterized.cluster)\n",
    "    return data_clusterized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster size\n",
    "\n",
    "def cluster_size (data) :\n",
    "    Cluster_size=pd.DataFrame({'trgNum':[], 'ldr':[],'Cluster_size':[]})\n",
    "    m=int(max(data.cluster))\n",
    "    data= data.sort_values(by=['cluster'])\n",
    "    for cluster in range(10000) :\n",
    "        print('cluster_size_percentage : ',cluster/100,end='\\r')\n",
    "        Cluster_size=pd.concat([Cluster_size,pd.DataFrame({'trgNum':[data.loc[data.cluster==cluster,'trgNum'].values[0]],'ldr':[data.loc[data.cluster==cluster,'ldr'].values[0]],'Cluster_size':[len(data[data.cluster==cluster])]})])\n",
    "    return(Cluster_size)\n",
    "\n",
    "Cluster_size=cluster_size(data_clusterized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the distribution of the cluster size\n",
    "Cluster_size['Cluster_size'].hist(bins=20)\n",
    "plt.title('Cluster size distribution')\n",
    "plt.ylabel('Entries')\n",
    "plt.xlabel('Cluster size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster by trgNum \n",
    "Cluster_by_trgNum=[len(Cluster_size[Cluster_size.trgNum==t]) for t in range (1,int(max(Cluster_size.trgNum))+1)]\n",
    "plt.hist(Cluster_by_trgNum,bins=10)\n",
    "plt.title('Cluster by trigger Number')\n",
    "plt.ylabel('Entries')\n",
    "plt.xlable('Number of cluster by trigger number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#computing barycenter\n",
    "def reduce_by_barycenter_new (data) :\n",
    "    data_sorted =data.sort_values(by=['cluster'])\n",
    "    data_reduced=pd.DataFrame({'trgNum':[],'ldr':[],'cluster':[],'Xbar':[],'Ybar':[]})\n",
    "    m=max(data_sorted.cluster)\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    n=0\n",
    "    for index, entry in data_sorted.iterrows() :\n",
    "        print('Reduction : ',(n*100/m),\" %\",end='\\r')\n",
    "        if entry.cluster == n :\n",
    "            X.append(entry.col)\n",
    "            Y.append(entry.row)\n",
    "        else :\n",
    "            e=pd.DataFrame({'trgNum':[entry.trgNum],'ldr':[entry.ldr],'cluster':[entry.cluster],'Xbar':[np.mean(X)],'Ybar':[np.mean(Y)]})\n",
    "            data_reduced=pd.concat([data_reduced,e])\n",
    "            X=[]\n",
    "            Y=[]\n",
    "            X.append(entry.col)\n",
    "            Y.append(entry.row)\n",
    "            n+=1\n",
    "    return data_reduced\n",
    "\n",
    "\n",
    "data_reduced=reduce_by_barycenter_new (data_clusterized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Efficiency (4 ladders hit for a trigger)\n",
    "n=0\n",
    "for t in range (10000):\n",
    "    data_trg=data_reduced[data_reduced.trgNum==t]\n",
    "    if len(data_trg[data_trg.ldr==1])>0 and len(data_trg[data_trg.ldr==2])>0 and len(data_trg[data_trg.ldr==3])>0 and len(data_trg[data_trg.ldr==4])>0 :\n",
    "        n+=1\n",
    "print('Efficiency : ',n/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the data \n",
    "\n",
    "def chi2 (xexp,xfit): #computing chi2\n",
    "    chi2 =0 \n",
    "    for i in range (len(xexp)):\n",
    "        chi2+=((xexp[i]-xfit[i])**2)/xexp[i]\n",
    "    return chi2\n",
    "\n",
    "def tracking (X,Y,Z0,t) :\n",
    "    slope_X, intercept_X, r_value, p_value, std_err= stats.linregress(Z0, X)\n",
    "    slope_Y, intercept_Y, r_value, p_value, std_err= stats.linregress(Z0, Y)\n",
    "    Mean_Residuals_X=np.sqrt(np.mean((slope_X*np.array(Z0)+intercept_X-np.array(X))**2))#quadratique\n",
    "    Mean_Residuals_Y=np.sqrt(np.mean((slope_Y*np.array(Z0)+intercept_Y-np.array(Y))**2))#quadratique\n",
    "    return pd.DataFrame({'trgNum':[t],'Mean_Residuals_X':[Mean_Residuals_X],'Mean_Residuals_Y':[Mean_Residuals_Y],'slope_X':[slope_X],'intercept_X':[intercept_X],'slope_Y':[slope_Y],'intercept_Y':[intercept_Y]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Alignement from the tracking : In this more precise alignement technique we compute all the residuals from a track (3 points fitting, distance from the track of the 4th one)\n",
    "\n",
    "def precise_alignement (data,Z0) :\n",
    "    Distances_X=[[],[],[],[]]\n",
    "    Distances_Y=[[],[],[],[]]\n",
    "    m=int(max(data.ldr))\n",
    "    for t in range(10000) :\n",
    "        data_trgNum=data[data.trgNum==t]\n",
    "        print (\"precise_alignement_percentage : \",t/100, end='\\r')\n",
    "        if (len(data_trgNum)==m and data_trgNum.ldr.nunique() == data_trgNum.ldr.size):\n",
    "            for k in range(1,m):\n",
    "                X=[]\n",
    "                Y=[]\n",
    "                Z=[]\n",
    "                for j in range (m):\n",
    "                    #if j!=k:\n",
    "                    X.append(data_trgNum.loc[data_trgNum.ldr==j+1,'Xbar'].values[0])\n",
    "                    Y.append(data_trgNum.loc[data_trgNum.ldr==j+1,'Ybar'].values[0])\n",
    "                    Z.append(Z0[j])\n",
    "                T=tracking (X,Y,Z,t)\n",
    "                distance_x=T.at[0,'slope_X']*Z0[k]+T.at[0,'intercept_X']-data_trgNum.loc[data_trgNum.ldr==k+1,'Xbar'].values[0]\n",
    "                distance_y=T.at[0,'slope_Y']*Z0[k]+T.at[0,'intercept_Y']-data_trgNum.loc[data_trgNum.ldr==k+1,'Ybar'].values[0]\n",
    "                Distances_X[k].append(distance_x)\n",
    "                Distances_Y[k].append(distance_y)\n",
    "    return pd.DataFrame({'dx':Distances_X,'dy':Distances_Y})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z corresponds to the original coordinates\n",
    "Z=[0,10.6*10000/30,145*10000/30,155.6*10000/30]\n",
    "Distances=precise_alignement(data_reduced,Z)\n",
    "print('x',np.mean(Distances['dx'][0]),np.mean(Distances['dx'][1]),np.mean(Distances['dx'][2]),np.mean(Distances['dx'][3]),'Y',np.mean(Distances['dy'][0]),np.mean(Distances['dy'][1]),np.mean(Distances['dy'][2]),np.mean(Distances['dy'][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving from the correction that we had previously\n",
    "def move (data,X,Y):\n",
    "    for i in range(1,int(max(data.ldr))) :\n",
    "        data.loc[data.ldr==i+1,'Xbar']=data[data.ldr==i+1].Xbar+np.mean(X[i])\n",
    "        data.loc[data.ldr==i+1,'Ybar']=data[data.ldr==i+1].Ybar+np.mean(Y[i])\n",
    "    return data\n",
    "\n",
    "\n",
    "data_aligned=data_reduced.copy()\n",
    "data_aligned=move(data_aligned,Distances['dx'],Distances['dy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing all the tracks for a run  (we do it on 10000 to avoid long running time)\n",
    "\n",
    "def make_tracks (data,Z) :\n",
    "    Tracks=pd.DataFrame({'trgNum':[],'Mean_Residuals_X':[],'Mean_Residuals_Y':[],'slope_X':[],'intercept_X':[],'slope_Y':[],'intercept_Y':[]})\n",
    "    m=int(max(data.ldr))\n",
    "    data= data.sort_values(by=['trgNum'])\n",
    "    for t in range(10000) :\n",
    "        print (\"make_tracks_percentage : \",t/100, end='\\r')\n",
    "        data_trgNum=data[data.trgNum==t]\n",
    "        if (len(data_trgNum)==m and data_trgNum.ldr.nunique() == data_trgNum.ldr.size):\n",
    "            X=[data_trgNum.loc[data_trgNum.ldr==i+1,'Xbar'].values[0] for i in range (m)]\n",
    "            Y=[data_trgNum.loc[data_trgNum.ldr==i+1,'Ybar'].values[0] for i in range (m)]\n",
    "            T=tracking (X,Y,Z,t)\n",
    "            Tracks=pd.concat([Tracks,T])\n",
    "    return Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tracks_aligned=make_tracks(data_aligned,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping on alignement\n",
    "DATA=[data_aligned]\n",
    "Tracks=[Tracks_aligned]\n",
    "for i in range (100) :\n",
    "    data=DATA[i].copy()\n",
    "    Distances=precise_alignement(data,Z)\n",
    "    DATA.append(move(data,Distances['dx'],Distances['dy']))\n",
    "    Tracks.append(make_tracks(data,Z))\n",
    "\n",
    "#displaying the evolution of residuals according to the iteration \n",
    "Residual=[]\n",
    "for i in range(len(Tracks)):\n",
    "    Residual.append(np.mean(Tracks[i].Mean_Residuals_Y))\n",
    "plt.scatter(np.arange(0,101,1),Residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#event display (t: trigger number, absi: Z coordinate, ordo: X or Y coordinate)\n",
    "\n",
    "def event_display(data,track,t,absi,ordo :str,label) :\n",
    "    Absi=np.array(absi)\n",
    "    plt.title(\"event display of \" +ordo +\" in function of Z\")\n",
    "    plt.scatter(Absi,data[data.trgNum==t][ordo+'bar'])\n",
    "    plt.plot(Absi,track.loc[track.trgNum==t,'slope_'+ordo].values[0]*Absi+track.loc[track.trgNum==t,'intercept_'+ordo].values[0],label=label)\n",
    "    \n",
    "\n",
    "event_display(data_aligned,Tracks_aligned,2000,Z,'X','aligned')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean event display (the average event)\n",
    "\n",
    "def mean_event_display(data,track,Z,ordo:str,label) :\n",
    "    Z=np.array(Z)\n",
    "    plt.scatter(Z,[np.mean(data.loc[data['trgNum'].isin(np.array(track.trgNum))&(data.ldr==i+1),ordo+'bar'])for i in range(max(data.ldr))])\n",
    "    plt.plot(Z,np.mean(track['slope_'+ordo])*Z+np.mean(track['intercept_'+ordo]),label=label)\n",
    "    plt.title(ordo+'(Z) in average, points: real, line: reconstructed track',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D mean event (no rotation)\n",
    "\n",
    "\n",
    "def mean_event_3d (data,Track):\n",
    "    fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "    # Make data.\n",
    "    X = np.arange(4096, 5120, 1)\n",
    "    Y = np.arange(0, 512, 1)\n",
    "    a=len(X)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    #Z could me changed according to a plane equation \n",
    "    Z0=np.zeros((len(Y),a))\n",
    "    Z=np.ones((len(Y),a))\n",
    "    Z1=Z*10.6*10000/30\n",
    "    Z2=Z*145*10000/30\n",
    "    Z3=Z*155.6*10000/30\n",
    "    # Plot the ladders\n",
    "    ax.plot_surface(X, Y, Z0,color='Grey',alpha=0.2)\n",
    "    ax.plot_surface(X, Y, Z1,color='Grey',alpha=0.2)\n",
    "    ax.plot_surface(X, Y, Z2,color='Grey',alpha=0.2)\n",
    "    ax.plot_surface(X, Y, Z3,color='Grey',alpha=0.2)\n",
    "    # plot the measured points\n",
    "    ax.scatter([np.mean(data.loc[data['trgNum'].isin(np.array(Track.trgNum))&(data.ldr==i+1),'Xbar'])for i in range(int(max(data.ldr)))],[np.mean(data.loc[data['trgNum'].isin(np.array(Track.trgNum))&(data_reduced.ldr==i+1),'Ybar'])for i in range(int(max(data.ldr)))],[1000,10.6*10000/30+1,145*10000/30+1,155.6*10000/30+1],color='r',marker='+',s=200)\n",
    "    #plot the reconstructed track\n",
    "    ax.plot(np.mean(Track['slope_X'])*np.array([1000,10.6*10000/30+1,145*10000/30+1,155.6*10000/30+1])+np.mean(Track['intercept_X']), np.mean(Track['slope_Y'])*np.array([1000,10.6*10000/30+1,145*10000/30+1,155.6*10000/30+1])+np.mean(Track['intercept_Y']),[1000,10.6*10000/30+1,145*10000/30+1,155.6*10000/30+1] ,color='r')\n",
    "    \n",
    "    #customization\n",
    "    ax.view_init(vertical_axis='y',azim=-45)\n",
    "    ax.set_zlim(0,55000)\n",
    "    ax.tick_params( labelsize = 8)\n",
    "    ax.set_ylim3d(0, 1024)\n",
    "    ax.set_xlim3d(4096, 5120)\n",
    "    ax.set_xlabel(\"Horizontal axis [pixels]\",fontsize=12)\n",
    "    ax.set_ylabel(\"Vertical axis [pixels]\",fontsize=12)\n",
    "    ax.set_zlabel(\"Beam axis [pixels]\",fontsize=12)\n",
    "    plt.title(\"Overview of the mean event, zoomed on the chip of interest\",fontsize=16)\n",
    "\n",
    "mean_event_3d(data_aligned,Tracks_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the plane of the ladder with an equation : a_x*x+a_y*y+a_z*z+cte=0\n",
    "def plan_echelle(theta,psi,phi,x,y,z) :\n",
    "    phiy,phiz,thetaz,thetax,psiy,psix=1,1,1,1,1,1\n",
    "    if theta== 0 : \n",
    "        psix,thetax=0,0\n",
    "    if phi== 0 : \n",
    "         phiy,psiy=0,0\n",
    "    if (phi!=0 and psi!=0) or (theta!=0 and psi!=0):\n",
    "        psix=np.sin(psi)\n",
    "        psiy=-np.cos(psi)\n",
    "        thetax=1\n",
    "        phiy=1\n",
    "    else :\n",
    "        psiy=1\n",
    "        psix=1\n",
    "    if phi!=0 :\n",
    "        phiz=-np.cos(phi)\n",
    "        phiy=np.sin(phi)\n",
    "    if theta!=0 :\n",
    "        thetaz=-np.cos(theta)\n",
    "        thetax=np.sin(theta)\n",
    "    a_x=psix*thetax\n",
    "    a_y=psiy*phiy\n",
    "    a_z=thetaz*phiz\n",
    "    cte=-(a_x*x+a_y*y+a_z*z)\n",
    "    return (pd.DataFrame({'a_x':[a_x],'a_y':[a_y],'a_z':[a_z],'cte':[cte]}))\n",
    "\n",
    "def intersect(t_x,t_y,c_x,c_y,P): #define the intersection of a track with a given plane P\n",
    "    z_inter=(-P.cte[0]-P.a_y[0]*c_y-P.a_x[0]*c_x)/(P.a_z[0]+P.a_y[0]*t_y+P.a_x[0]*t_x)\n",
    "    return z_inter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the tracks for a given ladder and for a given ladder and a given event\n",
    "\n",
    "def make_tracks_ladder (data,ldr) : \n",
    "    Tracks=pd.DataFrame({'trgNum':[],'Mean_Residuals_X':[],'Mean_Residuals_Y':[],'slope_X':[],'intercept_X':[],'slope_Y':[],'intercept_Y':[],'ldr':[],'Residual_X_'+str(ldr['id'][0]):[],'Residual_Y_'+str(ldr['id'][0]):[],'Residual_Z_'+str(ldr['id'][0]):[],'z_inter':[],'Residual_tot'+str(ldr['id'][0]):[]})\n",
    "    m=int(max(data.ldr))\n",
    "    data= data.sort_values(by=['trgNum'])\n",
    "    for t in range(10000) :\n",
    "        print (\"make_tracks_percentage : \",t/100, end='\\r')\n",
    "        data_trgNum=data[data.trgNum==t]\n",
    "        if (len(data_trgNum)==m and data_trgNum['ldr'].nunique() == data_trgNum['ldr'].size):\n",
    "            \n",
    "            X=[data_trgNum.loc[data_trgNum.ldr==i+1,'Xbar'].values[0] for i in range (m)]\n",
    "            Y=[data_trgNum.loc[data_trgNum.ldr==i+1,'Ybar'].values[0] for i in range (m)]\n",
    "            Z=[data_trgNum.loc[data_trgNum.ldr==i+1,'Z'].values[0] for i in range (m)] \n",
    "            \n",
    "            T=tracking (X,Y,Z,t)\n",
    "            T['ldr']=ldr['id']\n",
    "            P=plan_echelle(ldr.theta[0],ldr.psi[0],ldr.phi[0],ldr.x[0],ldr.y[0],ldr.z[0])\n",
    "            z_inter=intersect(T['slope_X'].values[0],T['slope_Y'].values[0],T['intercept_X'].values[0],T['intercept_Y'].values[0],P)\n",
    "            #we compute only the residual for the moved ladder.\n",
    "            T['Residual_X_'+str(ldr['id'][0])]=T['slope_X'].values[0]*z_inter+ T['intercept_X'].values[0] -X[ldr['id'][0]-1]\n",
    "            T['Residual_Y_'+str(ldr['id'][0])]=-T['slope_Y'].values[0]*z_inter+T['intercept_Y'].values[0]-Y[ldr['id'][0]-1]\n",
    "            T['Residual_Z_'+str(ldr['id'][0])]=z_inter-Z[ldr['id'][0]-1]\n",
    "            T['Residual_tot'+str(ldr['id'][0])]=np.sqrt(T['Residual_Z_'+str(ldr['id'][0])]**2+T['Residual_Y_'+str(ldr['id'][0])]**2+T['Residual_X_'+str(ldr['id'][0])]**2)\n",
    "            T['z_inter']=z_inter\n",
    "            Tracks=pd.concat([Tracks,T])\n",
    "            \n",
    "    return Tracks\n",
    "\n",
    "def make_tracks_ladder_event (data,ldr:,t:int) : # ldr is the ladder number and t the trigger number \n",
    "    m=int(max(data.ldr))\n",
    "    data_trgNum=data[data.trgNum==t]   \n",
    "    if (len(data_trgNum)==m and data_trgNum['ldr'].nunique() == data_trgNum['ldr'].size):\n",
    "        X=[data_trgNum.loc[data_trgNum.ldr==i+1,'Xbar'].values[0] for i in range (m)]\n",
    "        Y=[data_trgNum.loc[data_trgNum.ldr==i+1,'Ybar'].values[0] for i in range (m)]\n",
    "        Z=[data_trgNum.loc[data_trgNum.ldr==i+1,'Z'].values[0] for i in range (m)] \n",
    "        T=tracking (X,Y,Z,t)\n",
    "        T['ldr']=ldr['id']\n",
    "        P=plan_echelle(ldr.theta[0],ldr.psi[0],ldr.phi[0],ldr.x[0],ldr.y[0],ldr.z[0])\n",
    "        z_inter=intersect(T['slope_X'].values[0],T['slope_Y'].values[0],T['intercept_X'].values[0],T['intercept_Y'].values[0],P)\n",
    "        #we compute only the residual for the moved ladder.\n",
    "        T['Residual_X_'+str(ldr['id'][0])]=T['slope_X'].values[0]*z_inter+ T['intercept_X'].values[0] -X[ldr['id'][0]-1]\n",
    "        T['Residual_Y_'+str(ldr['id'][0])]=-T['slope_Y'].values[0]*z_inter+T['intercept_Y'].values[0]-Y[ldr['id'][0]-1]\n",
    "        T['Residual_Z_'+str(ldr['id'][0])]=z_inter-Z[ldr['id'][0]-1]\n",
    "        T['Residual_tot'+str(ldr['id'][0])]=np.sqrt(T['Residual_Z_'+str(ldr['id'][0])]**2+T['Residual_Y_'+str(ldr['id'][0])]**2+T['Residual_X_'+str(ldr['id'][0])]**2)\n",
    "        T['z_inter']=z_inter            \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the global and local derivatives\n",
    "\n",
    "def global_derivative_residual_event (data,dpsi,dtheta,dphi,dz,dx,dy,L,Track_init,t) : #inputs : movements that we want to try, Track_init=> all the inital tracks, L the ladder that you are working on\n",
    "    track0=Track_init[Track_init.trgNum==t]\n",
    "    data_moved=data.copy()\n",
    "    L_moved=pd.DataFrame({'id':[L.id[0]],'theta':[L.theta[0]+dtheta],'phi':[L.phi[0]+dphi],'psi':[L.psi[0]+dpsi],'x':[L.x[0]+dx],'y':[L.y[0]+dy],'z':[L.z[0]+dz]})\n",
    "    ldr=L['id'].values[0]\n",
    "\n",
    "    #Changing the data according to the given rotations and translations\n",
    "    if dtheta!=0 :\n",
    "        Norm1=np.sqrt((data_moved.loc[data_moved.ldr==ldr,'Xbar']**2)+((data_moved.loc[data_moved.ldr==ldr,'Z']-L.z[0])**2))\n",
    "        data_moved.loc[data_moved.ldr==ldr,'Xbar']=Norm1*np.cos(L_moved.theta[0])\n",
    "        data_moved.loc[data_moved.ldr==ldr,'Z']=Norm1*np.sin(L_moved.theta[0])+L.z[0]\n",
    "    if dphi!=0 :\n",
    "        Norm2=np.sqrt((data_moved.loc[data_moved.ldr==ldr,'Ybar']**2)+((data_moved.loc[data_moved.ldr==ldr,'Z']-L.z[0])**2))\n",
    "        data_moved.loc[data_moved.ldr==ldr,'Ybar']=Norm2*np.cos(L_moved.phi[0])\n",
    "        data_moved.loc[data_moved.ldr==ldr,'Z']=Norm2*np.sin(L_moved.phi[0])+L.z[0]\n",
    "    if dpsi!=0 :\n",
    "        Norm3=np.sqrt((data_moved.loc[data_moved.ldr==ldr,'Xbar']**2)+((data_moved.loc[data_moved.ldr==ldr,'Ybar'])**2))\n",
    "        data_moved.loc[data_moved.ldr==ldr,'Xbar']=data_moved.loc[data_moved.ldr==ldr,'Xbar']*np.cos(L_moved.psi[0])-data_moved.loc[data_moved.ldr==ldr,'Ybar']*np.sin(L_moved.psi[0])\n",
    "        data_moved.loc[data_moved.ldr==ldr,'Ybar']=data_moved.loc[data_moved.ldr==ldr,'Xbar']*np.sin(L_moved.psi[0])+data_moved.loc[data_moved.ldr==ldr,'Ybar']*np.cos(L_moved.psi[0])\n",
    "    data_moved.loc[data_moved.ldr==ldr,'Xbar']+=dx\n",
    "    data_moved.loc[data_moved.ldr==ldr,'Ybar']+=dy\n",
    "    data_moved.loc[data_moved.ldr==ldr,'Z']+=dz\n",
    "\n",
    "    #Compute the new track\n",
    "    track1=make_tracks_ladder_event(data_moved,L_moved,t)\n",
    "    Difference=track1['Residual_tot'+str(ldr)].values[0]-track0['Residual_tot'+str(ldr)].values[0]\n",
    "    return Difference,track1,track0, data_moved,L_moved #We deliver not really the derivative put the new difference (f(x+dx)-f(x)) we will divide by dx to get an approximation of the derivative\n",
    "\n",
    "def local_derivative_event (data,dx,dy,tx,ty,L,Track_init,t) : \n",
    "    track0=Track_init[Track_init.trgNum==t]\n",
    "    track1=track0.copy()\n",
    "    track1['slope_X']=track1['slope_X']+tx\n",
    "    track1['intercept_X']=track1['intercept_X']+dx\n",
    "    track1['slope_Y']=track1['slope_Y']+ty\n",
    "    track1['intercept_Y']=track1['intercept_Y']+dy\n",
    "    m=int(max(data.ldr))\n",
    "    data_trgNum=data[data.trgNum==t]\n",
    "    ldr=L['id'].values[0]\n",
    "    if (len(data_trgNum)==m and data_trgNum['ldr'].nunique() == data_trgNum['ldr'].size):\n",
    "        X=[data_trgNum.loc[data_trgNum.ldr==i+1,'Xbar'].values[0] for i in range (m)]\n",
    "        Y=[data_trgNum.loc[data_trgNum.ldr==i+1,'Ybar'].values[0] for i in range (m)]\n",
    "        Z=[data_trgNum.loc[data_trgNum.ldr==i+1,'Z'].values[0] for i in range (m)] \n",
    "        P=plan_echelle(L.theta[0],L.psi[0],L.phi[0],L.x[0],L.y[0],L.z[0])\n",
    "        z_inter=intersect(track1['slope_X'].values[0],track1['slope_Y'].values[0],track1['intercept_X'].values[0],track1['intercept_Y'].values[0],P)\n",
    "        #we compute only the residual for the moved ladder.\n",
    "        track1['Residual_X_'+str(L['id'][0])]=track1['slope_X'].values[0]*z_inter+ track1['intercept_X'].values[0] -X[ldr-1]\n",
    "        track1['Residual_Y_'+str(L['id'][0])]=-track1['slope_Y'].values[0]*z_inter+track1['intercept_Y'].values[0]-Y[ldr-1]\n",
    "        track1['Residual_Z_'+str(L['id'][0])]=z_inter-Z[ldr-1]\n",
    "        track1['Residual_tot'+str(L['id'][0])]=np.sqrt(track1['Residual_Z_'+str(L['id'][0])]**2+track1['Residual_Y_'+str(L['id'][0])]**2+track1['Residual_X_'+str(L['id'][0])]**2)\n",
    "        track1['z_inter']=z_inter \n",
    "    Difference=track1['Residual_tot'+str(ldr)].values[0]-track0['Residual_tot'+str(ldr)].values[0]\n",
    "    return Difference,track1,track0, data,L #We deliver not really the derivative put the new difference (f(x+dx)-f(x)) we will divide by dx to get an approximation of the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#making the CSV of derivatives and Residual for mille (only 1000 tracks)\n",
    "\n",
    "#labels : psi=50,theta=60,phi=70,z=80,x=90,y=100 and the unity number is the ladder number\n",
    "import csv \n",
    "def make_mille(data,name:str) :\n",
    "    Label=np.array([50,60,70,80,90,100])\n",
    "    d=0.000001\n",
    "    dos=open(name+'.csv','w',newline='')\n",
    "    writer=csv.writer(dos)\n",
    "    writer.writerow(['Iteration','NLC', 'derLc','NGL', 'derGl', 'label','rMeas', 'sigma'])\n",
    "    Ladders=[]\n",
    "    T=[]\n",
    "    for q in range(2,5): #Checking each ladder\n",
    "        print('Running on ladder : ',q)\n",
    "        Ladders.append(pd.DataFrame({'id':[q],'theta':[0],'phi':[0],'psi':[0],'x':[0],'y':[0],'z':[int(Z[q-1]*10000/30)]})) #Z is the initial distance at which the origin of the plane is\n",
    "        T.append(make_tracks_ladder (data,Ladders[q-2]))\n",
    "        t0=0\n",
    "        #Checking each event useful\n",
    "    for t in T[1].trgNum : #looping on the different events\n",
    "            t0+=1\n",
    "            if t0>1000: #keeping only the 1000 first ones (this is enough to compute millepede)\n",
    "                break\n",
    "            Data=[]\n",
    "            for l in range(2) : #Compute residual in X and then residual in Y \n",
    "                for i in range(2,5) :\n",
    "                    Labels=Label+i\n",
    "\n",
    "                    print('Running on ladder : ',i,', percentage : ', t0, end='\\r')\n",
    "                    Global=[]\n",
    "                    Local=[]\n",
    "                    j=0\n",
    "                        #Compute global derivatives\n",
    "                    while j <6:#looping on the different rotations and translations\n",
    "                        G=[0]*6\n",
    "                        G[j]=d\n",
    "                        psi,theta,phi,z,x,y=G[0],G[1],G[2],G[3],G[4],G[5]\n",
    "                        A=global_derivative_residual_event(data,psi,theta,phi,z,x,y,Ladders[i-2],T[i-2],t) \n",
    "                        a=A[1]['Residual_tot'+str(i)].values[0]-A[2]['Residual_tot'+str(i)].values[0]\n",
    "                        B=global_derivative_residual_event(data,-psi,-theta,-phi,-z,-x,-y,Ladders[i-2],T[i-2],t)\n",
    "                        b=B[1]['Residual_tot'+str(i)].values[0]-B[2]['Residual_tot'+str(i)].values[0]\n",
    "                        if (abs((a/d)-(b/(-d)))<0.01) : #We check that tha we are in a vincinity of the derivate in 0\n",
    "                            Global.append(a/d) #derivate evaluate in 0 (approximation)\n",
    "                            j+=1\n",
    "                            d=0.000001\n",
    "                        else :\n",
    "                            d=d/10\n",
    "                    #Compute local derivatives\n",
    "                    k=0\n",
    "                    d=0.00001\n",
    "                    while k<2 :#looping btw the interesect and the slope\n",
    "                        L=[0]*2\n",
    "                        L[k]=d\n",
    "                        dx,dy,tx,ty=(l-1)*L[0],(l-1)*L[1],l*L[0],l*L[1]\n",
    "                        C=local_derivative_event (data,dx,dy,tx,ty,Ladders[i-2],T[i-2],t)\n",
    "                        c=C[1]['Residual_tot'+str(i)].values[0]-C[2]['Residual_tot'+str(i)].values[0]\n",
    "                        E=local_derivative_event (data,-dx,-dy,-tx,-ty,Ladders[i-2],T[i-2],t)\n",
    "                        e=E[1]['Residual_tot'+str(i)].values[0]-E[2]['Residual_tot'+str(i)].values[0]\n",
    "                        if (abs((c/d)-(e/(-d)))<0.1) :\n",
    "                            Local.append(c/d) #derivate evaluate in 0 (approximation)\n",
    "                            k+=1\n",
    "                            d=0.00001\n",
    "                        else :\n",
    "                            d=d/10\n",
    "                    Local=np.array(Local)\n",
    "                    Global=np.array(Global)\n",
    "                    if l==0 :\n",
    "                        Data.append([t,4, str(Local),2, str(Global), str(Labels),T[i-2].loc[T[i-2].trgNum==t,'Residual_X_'+str(i)].values[0], 1])\n",
    "                    else :\n",
    "                        Data.append([t,4, str(Local),2, str(Global), str(Labels),T[i-2].loc[T[i-2].trgNum==t,'Residual_Y_'+str(i)].values[0], 1])\n",
    "            for row in Data: #just to put the data in a right format\n",
    "                    row = [cell.replace('\\n', ' ') if isinstance(cell, str) else cell for cell in row]\n",
    "                    print(row)\n",
    "                    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Be sure to create a Z column in your data before running make mille"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
